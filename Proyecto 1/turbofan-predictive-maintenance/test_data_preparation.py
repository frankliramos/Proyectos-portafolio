#!/usr/bin/env python3
"""
Test Data Preparation and Dashboard Compatibility

Este script verifica que los datos procesados son correctos y compatibles
con el dashboard y el modelo de inferencia.

Author: Franklin Ramos
Date: 2026-02-04
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np

# Add src to path
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))


def test_data_files():
    """Verifica que los archivos de datos procesados existen y tienen el formato correcto."""
    print("\n" + "="*70)
    print("TEST 1: VERIFICACIÃ“N DE ARCHIVOS DE DATOS")
    print("="*70)
    
    from src.config import PROCESSED_DATA_DIR
    
    train_file = PROCESSED_DATA_DIR / "fd001_prepared.parquet"
    test_file = PROCESSED_DATA_DIR / "fd001_test_prepared.parquet"
    
    # Check training file
    print(f"\nðŸ“„ Verificando {train_file.name}...")
    if not train_file.exists():
        print(f"   âœ— Archivo no existe: {train_file}")
        return False
    
    df_train = pd.read_parquet(train_file)
    print(f"   âœ“ Archivo existe")
    print(f"   âœ“ Shape: {df_train.shape}")
    print(f"   âœ“ Motores: {df_train['unit_id'].nunique()}")
    
    if len(df_train) < 10000:
        print(f"   âœ— ERROR: Muy pocas filas ({len(df_train)}). Â¿Solo tiene Ãºltimos ciclos?")
        return False
    print(f"   âœ“ Contiene todos los ciclos (>10k filas)")
    
    # Check test file
    print(f"\nðŸ“„ Verificando {test_file.name}...")
    if not test_file.exists():
        print(f"   âœ— Archivo no existe: {test_file}")
        return False
    
    df_test = pd.read_parquet(test_file)
    print(f"   âœ“ Archivo existe")
    print(f"   âœ“ Shape: {df_test.shape}")
    print(f"   âœ“ Motores: {df_test['unit_id'].nunique()}")
    
    if len(df_test) < 5000:
        print(f"   âœ— ERROR: Muy pocas filas ({len(df_test)}). Â¿Solo tiene Ãºltimos ciclos?")
        return False
    print(f"   âœ“ Contiene todos los ciclos (>5k filas)")
    
    # Check columns match
    required_cols = ['unit_id', 'time_cycles', 'RUL', 'op_setting_1', 'sensor_1']
    for col in required_cols:
        if col not in df_test.columns:
            print(f"   âœ— Columna faltante: {col}")
            return False
    print(f"   âœ“ Todas las columnas requeridas presentes")
    
    return True


def test_dashboard_compatibility():
    """Verifica que los datos son compatibles con el dashboard."""
    print("\n" + "="*70)
    print("TEST 2: COMPATIBILIDAD CON DASHBOARD")
    print("="*70)
    
    from src.config import PROCESSED_DATA_DIR
    
    # Load data like dashboard does
    data_path = PROCESSED_DATA_DIR / "fd001_test_prepared.parquet"
    df = pd.read_parquet(data_path)
    print(f"\nâœ“ Datos cargados: {df.shape}")
    
    # Rename columns like dashboard does
    if 'unit_id' in df.columns:
        df = df.rename(columns={'unit_id': 'id'})
    if 'time_cycles' in df.columns:
        df = df.rename(columns={'time_cycles': 'cycle'})
    print(f"âœ“ Columnas renombradas")
    
    # Validate
    if 'id' not in df.columns or 'cycle' not in df.columns:
        print(f"âœ— ERROR: Faltan columnas 'id' o 'cycle'")
        return False
    print(f"âœ“ ValidaciÃ³n de columnas OK")
    
    # Check distribution
    engine_ids = df['id'].unique()
    last_rul_per_engine = df.groupby('id')['RUL'].last()
    
    critical = (last_rul_per_engine < 30).sum()
    warning = ((last_rul_per_engine >= 30) & (last_rul_per_engine < 70)).sum()
    healthy = (last_rul_per_engine >= 70).sum()
    
    print(f"\nðŸ“Š DistribuciÃ³n de estados (Ãºltimo RUL por motor):")
    print(f"   ðŸ”´ CrÃ­ticos:  {critical:3d} ({critical/len(engine_ids)*100:5.1f}%)")
    print(f"   ðŸŸ¡ PrecauciÃ³n: {warning:3d} ({warning/len(engine_ids)*100:5.1f}%)")
    print(f"   ðŸŸ¢ Saludables: {healthy:3d} ({healthy/len(engine_ids)*100:5.1f}%)")
    
    if critical == len(engine_ids):
        print(f"\nâœ— ERROR: TODOS los motores estÃ¡n crÃ­ticos!")
        print(f"   Esto indica que el archivo solo tiene Ãºltimos ciclos.")
        return False
    
    if healthy == 0:
        print(f"\nâœ— ADVERTENCIA: NO hay motores saludables")
    
    print(f"\nâœ“ DistribuciÃ³n de estados es variada (no todos crÃ­ticos)")
    
    return True


def test_model_compatibility():
    """Verifica que los datos son compatibles con el modelo de inferencia."""
    print("\n" + "="*70)
    print("TEST 3: COMPATIBILIDAD CON MODELO")
    print("="*70)
    
    try:
        import joblib
        from src.config import FEATURE_COLS_FILE, PROCESSED_DATA_DIR
        
        # Load expected features
        if not FEATURE_COLS_FILE.exists():
            print(f"âœ— Archivo de features no existe: {FEATURE_COLS_FILE}")
            return False
        
        feature_cols = joblib.load(FEATURE_COLS_FILE)
        print(f"\nâœ“ Features esperadas por modelo: {len(feature_cols)}")
        print(f"   {feature_cols[:5]}...")
        
        # Load data
        df = pd.read_parquet(PROCESSED_DATA_DIR / "fd001_test_prepared.parquet")
        
        # Check if all features present
        missing = set(feature_cols) - set(df.columns)
        if missing:
            print(f"âœ— Features faltantes: {missing}")
            return False
        
        print(f"âœ“ Todas las features requeridas estÃ¡n presentes")
        
        # Test with one motor
        motor_data = df[df['unit_id'] == 1].sort_values('time_cycles')
        if len(motor_data) < 30:
            print(f"âœ— Motor 1 tiene menos de 30 ciclos ({len(motor_data)})")
            return False
        
        print(f"âœ“ Motor 1 tiene suficientes ciclos para predicciÃ³n ({len(motor_data)})")
        
        return True
        
    except ImportError as e:
        print(f"âš ï¸  No se pudo verificar compatibilidad con modelo: {e}")
        print(f"   (Es OK si no tienes todas las dependencias instaladas)")
        return True


def main():
    """Ejecuta todos los tests."""
    print("\n" + "="*70)
    print(" "*15 + "VERIFICACIÃ“N DE DATOS PROCESADOS")
    print("="*70)
    
    tests = [
        ("Archivos de datos", test_data_files),
        ("Compatibilidad con dashboard", test_dashboard_compatibility),
        ("Compatibilidad con modelo", test_model_compatibility),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\nâœ— ERROR en test '{test_name}': {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # Summary
    print("\n" + "="*70)
    print("RESUMEN DE TESTS")
    print("="*70)
    
    for test_name, result in results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"{status:8s} - {test_name}")
    
    all_passed = all(r for _, r in results)
    
    print("\n" + "="*70)
    if all_passed:
        print("âœ… TODOS LOS TESTS PASARON")
        print("="*70)
        print("\nðŸ’¡ Los datos estÃ¡n listos para usar en:")
        print("   - Dashboard (streamlit run app.py)")
        print("   - Notebooks de anÃ¡lisis")
        print("   - Predicciones con el modelo LSTM")
        print("\n" + "="*70)
        return 0
    else:
        print("âŒ ALGUNOS TESTS FALLARON")
        print("="*70)
        print("\nðŸ”§ SoluciÃ³n:")
        print("   Ejecuta: python prepare_all_data.py")
        print("   Para regenerar los datos procesados correctamente")
        print("\n" + "="*70)
        return 1


if __name__ == "__main__":
    sys.exit(main())
