{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa2ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /media/franklin/Respaldo 2/Proyectos portafolio/Proyecto 1\n",
      "sys.path[0]: /media/franklin/Respaldo 2/Proyectos portafolio/Proyecto 1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ajusta esta ruta al directorio raíz de tu proyecto (donde está la carpeta src)\n",
    "PROJECT_ROOT = Path().resolve().parent  # Si tu notebook está dentro de 'notebooks/', usa parent\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08012b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3943a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando en: cuda\n",
      "Número de features: 24\n",
      "NaNs por columna (train):\n",
      "op_setting_1    0\n",
      "op_setting_2    0\n",
      "op_setting_3    0\n",
      "sensor_1        0\n",
      "sensor_2        0\n",
      "sensor_3        0\n",
      "sensor_4        0\n",
      "sensor_5        0\n",
      "sensor_6        0\n",
      "sensor_7        0\n",
      "sensor_8        0\n",
      "sensor_9        0\n",
      "sensor_10       0\n",
      "sensor_11       0\n",
      "sensor_12       0\n",
      "sensor_13       0\n",
      "sensor_14       0\n",
      "sensor_15       0\n",
      "sensor_16       0\n",
      "sensor_17       0\n",
      "sensor_18       0\n",
      "sensor_19       0\n",
      "sensor_20       0\n",
      "sensor_21       0\n",
      "dtype: int64\n",
      "Epoch [1/30] - Loss: 6419.9264\n",
      "Epoch [5/30] - Loss: 1304.0812\n",
      "Epoch [10/30] - Loss: 227.5329\n",
      "Epoch [15/30] - Loss: 102.7406\n",
      "Epoch [20/30] - Loss: 68.4893\n",
      "Epoch [25/30] - Loss: 44.1681\n",
      "Epoch [30/30] - Loss: 31.2719\n",
      "\n",
      "--- RESULTADOS FINALES LSTM ---\n",
      "RMSE: 1.17\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import src.models as models\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define PROJECT_ROOT si no está definido (ajusta según tu estructura)\n",
    "PROJECT_ROOT = Path().resolve().parent  # Ajusta si tu notebook está en otra carpeta\n",
    "\n",
    "# Cargar los datos procesados\n",
    "train_processed = pd.read_parquet(PROJECT_ROOT / \"data\" / \"processed\" / \"fd001_prepared.parquet\")\n",
    "test_processed = train_processed.copy()  # O carga el de test si tienes uno específico\n",
    "\n",
    "# Normalizar nombres de columnas a los que usa el notebook (id, cycle)\n",
    "train_processed = train_processed.rename(columns={'unit_id': 'id', 'time_cycles': 'cycle'})\n",
    "test_processed  = test_processed.rename(columns={'unit_id': 'id', 'time_cycles': 'cycle'})\n",
    "\n",
    "# Eliminar columnas que están totalmente vacías (todas NaN) para evitar errores en el escalador\n",
    "train_processed.dropna(axis=1, how='all', inplace=True)\n",
    "test_processed = test_processed[train_processed.columns.intersection(test_processed.columns)].copy()\n",
    "\n",
    "# 1. Configuración y Hiperparámetros\n",
    "SEQUENCE_LENGTH = 30\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_RUL = 125\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Entrenando en: {DEVICE}\")\n",
    "\n",
    "# 2. Preparación de Datos (Escalado y Secuencias)\n",
    "feature_cols = [c for c in train_processed.columns if c not in ['id', 'cycle', 'RUL']]\n",
    "print(\"Número de features:\", len(feature_cols))\n",
    "print(\"NaNs por columna (train):\")\n",
    "print(train_processed[feature_cols].isna().sum())\n",
    "\n",
    "# Copia de trabajo\n",
    "train_data = train_processed.copy()\n",
    "test_data  = test_processed.copy()\n",
    "\n",
    "# Rellenar NaNs por motor (forward/backward fill), luego con la mediana global si aún quedan\n",
    "train_data[feature_cols] = train_data.groupby('id')[feature_cols].apply(\n",
    "    lambda g: g.ffill().bfill()\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "test_data[feature_cols] = test_data.groupby('id')[feature_cols].apply(\n",
    "    lambda g: g.ffill().bfill()\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "train_data[feature_cols] = scaler.fit_transform(train_data[feature_cols])\n",
    "test_data[feature_cols]  = scaler.transform(test_data[feature_cols])\n",
    "\n",
    "# Aplicar clipping al RUL de entrenamiento\n",
    "train_data['RUL'] = np.minimum(train_data['RUL'], MAX_RUL)\n",
    "\n",
    "# Función para crear secuencias\n",
    "def create_sequences(df, seq_len, features):\n",
    "    sequences, labels = [], []\n",
    "    for engine_id in df['id'].unique():\n",
    "        group = df[df['id'] == engine_id]\n",
    "        if len(group) >= seq_len:\n",
    "            data = group[features].values\n",
    "            target = group['RUL'].values\n",
    "            for i in range(len(group) - seq_len + 1):\n",
    "                sequences.append(data[i:i+seq_len])\n",
    "                labels.append(target[i+seq_len-1])\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(train_data, SEQUENCE_LENGTH, feature_cols)\n",
    "\n",
    "# Dataset PyTorch\n",
    "class RULDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(RULDataset(X_train_seq, y_train_seq), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 4. Inicializar Modelo\n",
    "importlib.reload(models)\n",
    "model = models.LSTMPredictor(input_dim=len(feature_cols), hidden_dim=64, num_layers=2).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 5. Bucle de Entrenamiento\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    losses = []\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(DEVICE), batch_y.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch [{epoch}/{EPOCHS}] - Loss: {np.mean(losses):.4f}\")\n",
    "\n",
    "# 6. Evaluación en Test (Última ventana de cada motor)\n",
    "model.eval()\n",
    "test_results = []\n",
    "y_true_test = []\n",
    "\n",
    "for engine_id in test_data['id'].unique():\n",
    "    group = test_data[test_data['id'] == engine_id]\n",
    "    if len(group) >= SEQUENCE_LENGTH:\n",
    "        last_seq = group[feature_cols].values[-SEQUENCE_LENGTH:]\n",
    "        last_seq = torch.tensor(last_seq, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(last_seq).cpu().item()\n",
    "            test_results.append(max(0, pred))\n",
    "            y_true_test.append(group['RUL'].values[-1])\n",
    "\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_true_test, test_results))\n",
    "print(f\"\\n--- RESULTADOS FINALES LSTM ---\")\n",
    "print(f\"RMSE: {rmse_lstm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0e2f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos de producción guardados en la carpeta /models/\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "\n",
    "# Crear carpeta models si no existe\n",
    "(PROJECT_ROOT / \"models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardar el estado del modelo (pesos)\n",
    "torch.save(model.state_dict(), PROJECT_ROOT / \"models\" / \"lstm_model_v1.pth\")\n",
    "\n",
    "# Guardar el escalador (fundamental para que los datos nuevos tengan la misma escala)\n",
    "joblib.dump(scaler, PROJECT_ROOT / \"models\" / \"scaler_v1.pkl\")\n",
    "\n",
    "# Guardar la lista de columnas de características para asegurar consistencia\n",
    "joblib.dump(feature_cols, PROJECT_ROOT / \"models\" / \"feature_cols_v1.pkl\")\n",
    "\n",
    "print(\"Archivos de producción guardados en la carpeta /models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6467a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor ID: 1\n",
      "RUL Predicho por LSTM: 1.73 ciclos\n"
     ]
    }
   ],
   "source": [
    "from src.inference import RULInference\n",
    "\n",
    "# Inicializar el motor de inferencia\n",
    "infer = RULInference(PROJECT_ROOT)\n",
    "\n",
    "# Tomar un motor aleatorio del set de test para probar\n",
    "sample_id = test_processed['id'].unique()[0]\n",
    "sample_engine_data = test_processed[test_processed['id'] == sample_id]\n",
    "\n",
    "# Realizar predicción\n",
    "predicted_rul = infer.predict(sample_engine_data)\n",
    "\n",
    "print(f\"Motor ID: {sample_id}\")\n",
    "print(f\"RUL Predicho por LSTM: {predicted_rul:.2f} ciclos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b17b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
